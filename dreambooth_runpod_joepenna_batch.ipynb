{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2c1ada",
   "metadata": {
    "id": "aa2c1ada"
   },
   "source": [
    "# Dreambooth\n",
    "### Notebook implementation by Joe Penna (@MysteryGuitarM on Twitter) - Improvements by David Bielejeski\n",
    "\n",
    "### Instructions\n",
    "- Sign up for RunPod here: https://runpod.io/?ref=n8yfwyum\n",
    "    - Note: That's my personal referral link. Please don't use it if we are mortal enemies.\n",
    "\n",
    "- Click *Deploy* on either `SECURE CLOUD` or `COMMUNITY CLOUD`\n",
    "\n",
    "- Follow the rest of the instructions in this video: https://www.youtube.com/watch?v=7m__xadX0z0#t=5m33.1s\n",
    "\n",
    "Latest information on:\n",
    "https://github.com/JoePenna/Dreambooth-Stable-Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b971cc0",
   "metadata": {
    "id": "7b971cc0"
   },
   "source": [
    "## Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2AsGA1xpNQnb",
   "metadata": {
    "id": "2AsGA1xpNQnb"
   },
   "outputs": [],
   "source": [
    "%cd /workspace/Dreambooth-Stable-Diffusion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
   "metadata": {
    "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BUILD ENV\n",
    "!pip install omegaconf\n",
    "!pip install einops\n",
    "!pip install pytorch-lightning==1.6.5\n",
    "!pip install test-tube\n",
    "!pip install transformers\n",
    "!pip install kornia\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install setuptools==59.5.0\n",
    "!pip install pillow==9.0.1\n",
    "!pip install torchmetrics==0.6.0\n",
    "!pip install -e .\n",
    "!pip install protobuf==3.20.1\n",
    "!pip install gdown\n",
    "!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    "!pip install -qq \"ipywidgets>=7,<8\"\n",
    "!pip install huggingface_hub\n",
    "!pip install ipywidgets==7.7.1\n",
    "!pip install captionizer==1.0.1\n",
    "!pip install google.cloud.storage\n",
    "!pip install protobuf==3.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95391dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\", auth=(\"yansong\", \"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\"))\n",
    "with open('model.ckpt', 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS=/workspace/Dreambooth-Stable-Diffusion/credentials/dev.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07a5df",
   "metadata": {
    "id": "ed07a5df"
   },
   "source": [
    "Training teaches your new model both your token **but** re-trains your class simultaneously.\n",
    "\n",
    "From cursory testing, it does not seem like reg images affect the model too much. However, they do affect your class greatly, which will in turn affect your generations.\n",
    "\n",
    "You can either generate your images here, or use the repos below to quickly download 1500 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f9ff0c-b529-4c7c-8e26-8388d70a5d91",
   "metadata": {
    "id": "67f9ff0c-b529-4c7c-8e26-8388d70a5d91"
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    " assert len(imgs) == rows*cols\n",
    "\n",
    " w, h = imgs[0].size\n",
    " grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    " grid_w, grid_h = grid.size\n",
    "\n",
    " for i, img in enumerate(imgs):\n",
    "  grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    " return grid\n",
    "\n",
    "def download_image(url):\n",
    " try:\n",
    "  response = requests.get(url)\n",
    " except:\n",
    "  return None\n",
    " return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def list_blobs(bucket_name, folder_name):\n",
    "    urls = []\n",
    "    client = storage.Client()\n",
    "    for blob in client.list_blobs(bucket_name, prefix=folder_name):\n",
    "        # print(blob.name)\n",
    "        gcs_url = 'https://%(bucket)s.storage.googleapis.com/%(file)s' % {'bucket':bucket_name, 'file':blob.name}\n",
    "        urls.append(gcs_url)\n",
    "    return urls\n",
    "\n",
    "\n",
    "bucket_name = \"imageappco-business\"\n",
    "elems = [\n",
    " \"jielunzhou\",\n",
    " \"chasebailey\",\n",
    " \"alondeswilliams\",\n",
    " \"dasima\",\n",
    " \"linjunjie\",\n",
    " \"zunlong\",\n",
    " \"wanglihong\",\n",
    " \"gru\",\n",
    "]\n",
    "\n",
    "ckptPath = 'model.ckpt'\n",
    "\n",
    "for elem in elems: \n",
    "    print(elem + \"start\")\n",
    "    # GENERATE 200 images - Optional\n",
    "    self_generated_files_prompt = \"person\" #@param {type:\"string\"}\n",
    "    self_generated_files_count = 200 #@param {type:\"integer\"}\n",
    "\n",
    "    !python scripts/stable_txt2img.py \\\n",
    "     --seed 10 \\\n",
    "     --ddim_eta 0.0 \\\n",
    "     --n_samples 1 \\\n",
    "     --n_iter {self_generated_files_count} \\\n",
    "     --scale 10.0 \\\n",
    "     --ddim_steps 50 \\\n",
    "     --ckpt {ckptPath} \\\n",
    "     --prompt {self_generated_files_prompt}\n",
    "\n",
    "    dataset=self_generated_files_prompt\n",
    "\n",
    "    !mkdir -p regularization_images/{dataset}\n",
    "    !mv outputs/txt2img-samples/*.png regularization_images/{dataset}\n",
    "\n",
    "# Zip up the files for downloading and reuse.\n",
    "# Download this file locally so you can reuse during another training on this dataset\n",
    "    !apt-get update\n",
    "    !apt-get install -y zip\n",
    "    !zip -r regularization_images.zip regularization_images/{dataset}\n",
    "\n",
    "\n",
    "\n",
    "    print('download source image file')\n",
    "    folder_name = elem\n",
    "    \n",
    "    urls = list_blobs(bucket_name, folder_name)\n",
    "    print(urls)\n",
    "    \n",
    "    !rm -rf ./training_images/*\n",
    "    images = list(filter(None,[download_image(url) for url in urls]))\n",
    "    save_path = \"./training_images\"\n",
    "    if not os.path.exists(save_path):\n",
    "     os.mkdir(save_path)\n",
    "    [image.save(f\"{save_path}/{i}.png\", format=\"png\") for i, image in enumerate(images)]\n",
    "    image_grid(images, 1, len(images))\n",
    "\n",
    "\n",
    "\n",
    "    print('Training')\n",
    "\n",
    "# Training\n",
    "\n",
    "# This isn't used for training, just to help you remember what your trained into the model.\n",
    "    project_name = \"yansong\"\n",
    "\n",
    "# MAX STEPS\n",
    "# How many steps do you want to train for?\n",
    "    max_training_steps = 2000\n",
    "\n",
    "# Match class_word to the category of the regularization images you chose above.\n",
    "    class_word = \"person\" # typical uses are \"man\", \"person\", \"woman\"\n",
    "\n",
    "# This is the unique token you are incorporating into the stable diffusion model.\n",
    "    token = folder_name\n",
    "\n",
    "\n",
    "    reg_data_root = \"/workspace/Dreambooth-Stable-Diffusion/regularization_images/\" + dataset\n",
    "\n",
    "    !rm -rf training_images/.ipynb_checkpoints\n",
    "    !python \"main.py\" \\\n",
    "     --base configs/stable-diffusion/v1-finetune_unfrozen.yaml \\\n",
    "     -t \\\n",
    "     --actual_resume {ckptPath} \\\n",
    "     --reg_data_root \"{reg_data_root}\" \\\n",
    "     -n \"{project_name}\" \\\n",
    "     --gpus 0, \\\n",
    "     --data_root \"/workspace/Dreambooth-Stable-Diffusion/training_images\" \\\n",
    "     --max_training_steps {max_training_steps} \\\n",
    "     --class_word \"{class_word}\" \\\n",
    "     --token \"{token}\" \\\n",
    "     --no-test\n",
    "\n",
    "\n",
    "    print('copy model')\n",
    "\n",
    "    # Copy the checkpoint into our `trained_models` folder\n",
    "\n",
    "    directory_paths = !ls -d logs/*\n",
    "    last_checkpoint_file = directory_paths[-1] + \"/checkpoints/last.ckpt\"\n",
    "    training_images = !find training_images/*\n",
    "    date_string = !date +\"%Y-%m-%dT%H-%M-%S\"\n",
    "    file_name = date_string[-1] + \"_\" + project_name + \"_\" + str(len(training_images)) + \"_training_images_\" +  str(max_training_steps) + \"_max_training_steps_\" + token + \"_token_\" + class_word + \"_class_word.ckpt\"\n",
    "\n",
    "    file_name = file_name.replace(\" \", \"_\")\n",
    "\n",
    "    !mkdir -p trained_models\n",
    "    !mv \"{last_checkpoint_file}\" \"trained_models/{file_name}\"\n",
    "    \n",
    "    ckptPath = \"/workspace/Dreambooth-Stable-Diffusion/trained_models/\"+file_name\n",
    "\n",
    "    print(\"Download your trained model file from trained_models/\" + file_name + \" and use in your favorite Stable Diffusion repo!\")\n",
    "\n",
    "    print('create image by trained model')\n",
    "    !python scripts/stable_txt2img.py \\\n",
    "     --ddim_eta 0.0 \\\n",
    "     --n_samples 1 \\\n",
    "     --n_iter 4 \\\n",
    "     --scale 7.0 \\\n",
    "     --ddim_steps 50 \\\n",
    "     --bucket {bucket_name} \\\n",
    "     --output {folder_name} \\\n",
    "     --outdir \"outputs/txt2img-samples/{folder_name}\" \\\n",
    "     --ckpt \"/workspace/Dreambooth-Stable-Diffusion/trained_models/{file_name}\" \\\n",
    "     --prompt \"{folder_name} person as a masterpiece portrait painting by John Singer Sargent in the style of Rembrandt\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
